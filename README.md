# COMP-305-GROUP-18
TODO List:
  > Development of bruto force method --> done
  > Implementing parser --> done
  > Implementing outputer --> done
  > Using set to decrease the number of l values --> done
  > Constructing l values from the distinct scores of the players (withSet algorithm) --> done
  > Augmentation to withSet algorithm with sums and indexes arrays --> done
  > Implementation of solution with augmentation in c --> done
  > Constructing histogram as a solution --> done
  > Randomized Test Case Generator --> done
  > Other approaches such as using histogram and FFT were tried --> done
  > Ideas to improve best yet solution --> done
  > Monte Carlo method -> use each l value with some probability --> done
  > Calculating of complexities of each algorithm (withSet, solution.c, mc) --> done
  > Analyze important l values --> not done
  > Preparation of presentation --> done
  > Constructing plots with different n and m values versus runtime --> done
  > Constructing lemma to prove our hypthesis about not using all the l values --> done

How to run the codes?
Note: <filename> should be the path to the file
1.withSet.py (in python_files directory)
> python3 withSet.py <filename>
-You need to give the pathway of a test case input file (test cases can be found in inputs folder)
-Final results can be found in output1.txt
2.mc.py (in python_files directory)
>rm ./../numbersMC.txt
>rm ./../outputs/outputMC.txt
> python3 withSet.py <filename>
-When running it first time remove numbersMC.txt and outputMC.txt as they need to be generated by mc.py to be used on the second run (and also on those that follow).
-You need to give the pathway of a test case input file (test cases can be found in inputs folder)
-Final results can be found in outputMC.txt
3.solution.c (in main branch)
>make
>./solution <filename>
-After compiling the code, you need to give the pathway of a test case input file (test cases can be found in inputs folder)
-Final results can be found in outputC.txt

Results of the test cases:
Results of the baby_comp_1.txt for each algorithm can be found under /outputs/outputForTestCase1/.
Results of the baby_comp_2.txt for each algorithm can be found under /outputs/outputForTestCase2/.
Results of the baby_comp_3.txt for each algorithm can be found under /outputs/outputForTestCase3/.
Results of the baby_comp_4.txt for each algorithm can be found under /outputs/outputForTestCase4/.

Runtime Results:
Test case 1:
Runtime of withSet.py: 0.036s
Runtime of mc.py: 0.035s
Runtime of solution.c: 0.005s
Test case 2:
Runtime of withSet.py: 0.033s
Runtime of mc.py: 0.035s
Runtime of solution.c: 0.004s
Test case 3:
Runtime of withSet.py: 0.032s: 
Runtime of mc.py: 0.038s
Runtime of solution.c: 0.004s
Test case 4:
Runtime of withSet.py: 46.717s
Runtime of mc.py: 0.326s
Runtime of solution.c: 4.861s

Summary:
Brute Force:
In order to understand the problem correctly, we used brute force method. In this method maximum possible l value was found and all l values were tried until 1 (inclusive) and the orders were found for each.
Then the minimum orders were returned. 
Using Set:
To improve this method, we decided not to try all possible l values and implemented an algorithm withSet.py. We used only the distinct scores of the players as possible l values by using set data structure. 
We tried all these l values in descending order to find the minimum placements of the players.
We saw that deciding on the l values to be tried is critical for the complexity and run time of the algorithm. 
Augmentation:
Our most efficient method (solution.c) is using augmentation added to the previous algorithm (withSet.py). 
One of the augmentations is to keep track of the total scores of each player in an array which is used later for each l value trial in order not to recalculate the total scores of each player. Only the changes in the scores are added to these total scores to update them for each l. 
Another augmentation is an array to keep the index of the last changed score for each player. This augmentation is performed in order to decrease the number of iteration while comparing the l value and players' scores.
By keeping the total scores and the index of the last changed score for each player, we do not need to update the scores that were updated with the previous l values.
Monte Carlo:
Another method we used was Monte Carlo to decrease the number of l values tried. In this method, probability was taken as 1/number of goal posts (roundCount in mc.py). 
This method works very fast but it does not give the correct output all the time. With the 1/num of goal posts probability l values are selected from the file and 
total scores of the players were updated according to selected l values and minimum final placements were calculated.  
Moreover, we tried two different approaches to solve the problems. These approaches are histogram and FFT. However, since they did not give the correct answer and runtimes are 
too high, we did not move on those methods.

How does solution.c work?
1. Test case file path is taken.
2. File is parsed into players and scores of the players are sorted in descending order using insertion sort and players' scores are stored in numbers array.
3. With insert_number method, distinct l values are added into an array (l_values) and size of the array is returned.
4. With calculate_sums method, each player's total scores are calculated and added into sums array.
5. Calculate_orders method is created for finding the final places of each player using their total scores in the sums array. Without changing any scores initially, orders are found and stored in min_orders array.
6. k array is defined to store the index of the last changed score value of each player. At the begining k is initialized as 0 array with size n(number of players).
7. old_l variable is defined to be the last used l value from the l_values array.
8. All distinct l values were traveled with for loop.
	8.1. All players are travelled with for loop.
	8.1.1. Corresponding sum value of the player was updated according to current l value and old_l value by using the corresponding last changed score's index stored in k.
		(sums[player number] += (k[player number]* (l - old_l)))
	8.1.2. dv variable is defined as 0.
	8.1.3 While loop is created to travel the scores that are larger than or equal to l. In this loop, the difference between score and l value is added to dv.
	8.1.4 dv is subtracted from the corresponding player's sum in sums array to update the total score value according to current l.
	8.2 Orders of the player are found with calculate_orders method with respect to their updated total scores in sums array.
	8.3 Using compare_orders method, previous order and the current order of the players are compared and if current order is smaller, it is saved to min_orders array that stores the minimum places.
	8.4 old_l value is updated with the current l value. For loop continues with the next l value from step 8.1.
9. After completion of step 8, min_orders array is written into the file outputC.txt to store the final minimum places of the players.
		




Lemma:
Using scores as l values that do not exist in the set of all scores of all players, do not have an effect on minimum orders.

Proof:
Let p1,p2 be players with the following ordering (in descending order) of scores:
p1  = [k+j, ..., k, k-y1, ...]
p2 = [k+u, ..., k, k-y2,...],

where y1,y2 > i, p1 has c1 elements >= k, p2 has c2 elements >= k [These are all to the left of k in the above arrays]
k > k-i > k-y1, k-y2 (Condition 1.1)
where k-i does not exist in either p1 or p2. Also, c1 > c2; so that p1 has more elems >= k than p2.

When the l value is k:
Case 1: sum(p1) < sum(p2):
  If we use k-i then the ordering will not change. This is due to c1 being larger than c2. That means that p1 has more elements that decrease by i,
  so sum'(p1) = sum(p1) - c1 * i, whereas  sum'(p2) = sum(p2) - c2 * i => sum'(p1) < sum'(p2), for all i that satisfy the above condition (1.1)
  Thus, looking at an intermediate value in this case does not change anyting since c1 and c2 remain constant.

Case 2: sum(p1) = sum(p2):
In this case sum'(p1) < sum'(p2) when l value is k-i, however the same effect will be achieved at max(k-y1,k-y2)
Thus, looking at an intermediate value in this case does not change anything that wouldn't have been changed at a non-intermediate value of k-y1 or k-y2.

Case 3: sum(p1) > sum(p2):
In this case, if we do not have sum'(p1) < sum'(p2) for any intermediate value than the minimum orders will not change. If we have that relation then reducing further to a non-intermediate value would preserve this relation since c1, c2 are constants and the difference sum(p1)-sum(p2) will only get lower (more negative) as we decrease the i value that gives k-i for the l value.
Thus, looking at an intermediate value in this case does not give any min-ordering that wouldn't have come from any non-intermediate value lower than this.

Thus in all of the possible cases we do not gain any new min-ordering information from scores that do not exist in the players' arrays.


We have many files in git, we did not delete them as they show the other things we have tried aside from the final solution.
Here is a list of them and their brief explanations:
1- inputs directory: This directory stores all of the input test cases. Some of them are the given test cases and some of them are randomly generated by our python rng test case generator code.
2- outputs directory: This directory is used to direct outputs of code. Also, the outputs of test cases for our main solutions are placed here.
3- images directory: This directory stores three images which are result of our visual data analysis
4- data.m: This is the MATLAB file we used to plot the complexity analysis. It has the measured time data points in it as code.
5- ideas.txt: This file has the ideas we brainstormed while working as a group on zoom calls.
6- lemmas.txt: We tried to find lemmas that would make our algorithm work faster. Also, we wrote the lemmas we used and tried to find intuitive proofs for them so that we knew our ideas were working correctly.
7- Makefile: This is the makefile for our c code, which is the most promising solution.
8- solution.c: This is the only solution we wrote in c. When we saw that unoptimised version of this algorithm was promising we decided to optimize it and write it in c.
9- numbersMC.txt: This is used by mc.py. Make sure this file does not exist in the initial call of mc.py or it won't work. Basically we want mc.py to create it at the first call with the test case so that in the second call it can use it. Similarly under outputs we have outputMC.txt that should also be deleted beforehand.
10- Images of runtimes: These were used to gather information for the presentation.
11- python_files: This is where all of our python code is. The rest of the files I will describe are in this folder.
12- toy_example.txt: This was the initial code we wrote to understand the problem's input->output relation on a simple example given in the pdf.
13- statistical_view.py: This was used to get some statistical information about a given input's number-min_order relations
14- withSet.py: This was the inital solution we thought of. Using a set to get all distinct l values.
15- random_test_case_generator.py: We wrote this to generate random test cases and check the correctness and time of a newly thought idea.
16- parser.py: We used this in our code to read the data. Depending on the need we have a couple different methods of reading.
17- Outputer.py: We used this to output the min orders
18- nonuniquekeys.py: This one did not work. It was based on using values that were not unique, in other words the values that repeated. However, it did not work as any value that is not the largest repeats as the larger ones are set to be equal to that value.
19- montecarlo.py: This was a trial to do montecarlo approach. This isn't our main monte carlo solution.
20- mc.py: This is our main monte carlo solution algorithm.
21- lValueArrays.py: This is our main algorithm written in python without any optimization.
22- histogramForEach.py: We tried to represent the arrays as histograms.
23- Hist.py: A simple implementation of histogram.
24- doubleHistogram.py: Keeping l values as histogram as well
25- contributionToIdea2.py: This was a thought exercise
26- augmentation.py: We tried to remove the shared maximum numbers at each iteration. It did not do that well on computation times.